# AITO 2.0 - Docker Compose Configuration
# Full infrastructure for autonomous AI CEO system

version: '3.8'

# ============================================
# SHARED CONFIGURATION (YAML Anchors)
# ============================================
x-agent-base-env: &agent-base-env
  POSTGRES_URL: postgresql://${POSTGRES_USER:-aito}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-aito}
  REDIS_URL: redis://redis:6379
  OLLAMA_URL: http://ollama:11434
  QDRANT_URL: http://qdrant:6333
  DRY_RUN: ${DRY_RUN:-false}
  # GitHub Workspace
  GITHUB_TOKEN: ${GITHUB_TOKEN}
  GITHUB_ORG: ${GITHUB_ORG:-Brunzendorf}
  WORKSPACE_REPO_URL: ${WORKSPACE_REPO_URL:-https://github.com/Brunzendorf/shibc-workspace.git}
  WORKSPACE_BRANCH: ${WORKSPACE_BRANCH:-main}
  WORKSPACE_SKIP_PR: ${WORKSPACE_SKIP_PR:-false}
  # LLM Routing Configuration (claude-only until Gemini quota resets or subscription)
  LLM_ROUTING_STRATEGY: ${LLM_ROUTING_STRATEGY:-claude-only}
  LLM_ENABLE_FALLBACK: ${LLM_ENABLE_FALLBACK:-false}
  LLM_PREFER_GEMINI: ${LLM_PREFER_GEMINI:-false}
  GEMINI_API_KEY: ${GEMINI_API_KEY}
  GEMINI_DEFAULT_MODEL: ${GEMINI_DEFAULT_MODEL:-gemini-2.0-flash-exp}
  GEMINI_MONTHLY_QUOTA: ${GEMINI_MONTHLY_QUOTA:-10000000}
  # Session Pool (EXPERIMENTAL - reduces token usage by ~80%)
  SESSION_POOL_ENABLED: ${SESSION_POOL_ENABLED:-false}
  SESSION_MAX_LOOPS: ${SESSION_MAX_LOOPS:-50}
  SESSION_IDLE_TIMEOUT_MS: ${SESSION_IDLE_TIMEOUT_MS:-1800000}

services:
  # ============================================
  # TIER 1: INFRASTRUCTURE (Always Running)
  # ============================================

  postgres:
    image: pgvector/pgvector:pg15
    container_name: aito-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-aito}
      POSTGRES_USER: ${POSTGRES_USER:-aito}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD required}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-aito}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - aito-network

  redis:
    image: redis:7-alpine
    container_name: aito-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - aito-network

  # ============================================
  # TIER 2: AI INFRASTRUCTURE (Always Running)
  # ============================================

  ollama:
    image: ollama/ollama:latest
    container_name: aito-ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - aito-network

  # Ollama Model Initializer - pulls required models on startup
  ollama-init:
    image: curlimages/curl:latest
    container_name: aito-ollama-init
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Pulling Ollama models..."
        # Embedding model for RAG (multilingual, 1024 dims, 72% accuracy)
        curl -X POST http://ollama:11434/api/pull -d '{"name": "bge-m3"}'
        echo "bge-m3 pulled"
        # Optional: Smaller embedding model as fallback
        curl -X POST http://ollama:11434/api/pull -d '{"name": "nomic-embed-text"}'
        echo "nomic-embed-text pulled"
        # LLM for text generation (archive-worker, fallback)
        curl -X POST http://ollama:11434/api/pull -d '{"name": "llama3.2:3b"}'
        echo "llama3.2:3b pulled"
        echo "All models ready!"
    networks:
      - aito-network
    restart: "no"

  qdrant:
    image: qdrant/qdrant:latest
    container_name: aito-qdrant
    restart: unless-stopped
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'exec 3<>/dev/tcp/127.0.0.1/6333 && echo OK'"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - aito-network

  # ============================================
  # TIER 3: WORKFLOW & AUTOMATION
  # ============================================

  n8n:
    image: n8nio/n8n:latest
    container_name: aito-n8n
    restart: unless-stopped
    environment:
      N8N_BASIC_AUTH_ACTIVE: "true"
      N8N_BASIC_AUTH_USER: ${N8N_USER:-admin}
      N8N_BASIC_AUTH_PASSWORD: ${N8N_PASSWORD:-admin}
      N8N_ENCRYPTION_KEY: ${N8N_ENCRYPTION_KEY:?N8N_ENCRYPTION_KEY required}
      WEBHOOK_URL: ${N8N_WEBHOOK_URL:-http://localhost:5678}
      GENERIC_TIMEZONE: UTC
    volumes:
      - n8n_data:/home/node/.n8n
      - ./n8n-workflows:/home/node/workflows:ro
    ports:
      - "5678:5678"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://127.0.0.1:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - aito-network

  # ============================================
  # ORCHESTRATOR (Container Manager)
  # ============================================

  orchestrator:
    build:
      context: .
      dockerfile: docker/Dockerfile.orchestrator
      args:
        GIT_HASH: ${GIT_HASH:-unknown}
        INSTALL_CLAUDE_CLI: ${INSTALL_CLAUDE_CLI:-true}
        INSTALL_GEMINI_CLI: ${INSTALL_GEMINI_CLI:-true}
        INSTALL_CODEX_CLI: ${INSTALL_CODEX_CLI:-false}
    container_name: aito-orchestrator
    restart: unless-stopped
    environment:
      NODE_ENV: production
      LOG_LEVEL: ${LOG_LEVEL:-info}
      DRY_RUN: ${DRY_RUN:-false}
      POSTGRES_URL: postgresql://${POSTGRES_USER:-aito}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-aito}
      REDIS_URL: redis://redis:6379
      PORTAINER_URL: http://portainer:9000
      PORTAINER_API_KEY: ${PORTAINER_API_KEY}
      PORTAINER_ENV_ID: ${PORTAINER_ENV_ID:-4}
      COMPOSE_PROJECT: ${COMPOSE_PROJECT:-shibc-aito}
      OLLAMA_URL: http://ollama:11434
      QDRANT_URL: http://qdrant:6333
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
      TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID}
      TELEGRAM_ADMIN_CHAT_ID: ${TELEGRAM_ADMIN_CHAT_ID}
      SENDGRID_API_KEY: ${SENDGRID_API_KEY}
      ADMIN_EMAIL: ${ADMIN_EMAIL}
      # Data fetcher API keys
      NEWS_API_KEY: ${NEWS_API_KEY}
      COINGECKO_API_KEY: ${COINGECKO_API_KEY}
      # GitHub (for backlog grooming)
      GITHUB_TOKEN: ${GITHUB_TOKEN}
      GITHUB_ORG: ${GITHUB_ORG:-Brunzendorf}
      # LLM API Keys for CLIs
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      # LLM Routing (from x-common-env)
      LLM_ROUTING_STRATEGY: ${LLM_ROUTING_STRATEGY:-claude-only}
      LLM_ENABLE_FALLBACK: ${LLM_ENABLE_FALLBACK:-false}
      LLM_PREFER_GEMINI: ${LLM_PREFER_GEMINI:-false}
      GEMINI_DEFAULT_MODEL: ${GEMINI_DEFAULT_MODEL:-gemini-2.5-flash}
    volumes:
      - ./profiles:/app/profiles:ro
      - orchestrator_logs:/app/logs
      - shared_claude_config:/app/.claude
      - shared_gemini_config:/app/.gemini
      - shared_openai_config:/app/.openai
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      portainer:
        condition: service_started
      qdrant:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - aito-network

  # ============================================
  # HEAD LAYER AGENTS (CEO + DAO)
  # ============================================

  ceo-agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
      args:
        INSTALL_CLAUDE_CLI: ${INSTALL_CLAUDE_CLI:-true}
        INSTALL_GEMINI_CLI: ${INSTALL_GEMINI_CLI:-true}
        INSTALL_CODEX_CLI: ${INSTALL_CODEX_CLI:-false}
    container_name: aito-ceo
    restart: unless-stopped
    environment:
      <<: *agent-base-env
      AGENT_TYPE: ceo
      AGENT_PROFILE: /app/profiles/ceo.md
      LOOP_INTERVAL: 900
    volumes:
      - ./profiles:/app/profiles:ro
      - ceo_memory:/app/memory
      - shared_claude_config:/app/.claude
      - shared_gemini_config:/app/.gemini
      - shared_openai_config:/app/.openai
      - ./workspace:/app/workspace
    depends_on:
      orchestrator:
        condition: service_healthy
    networks:
      - aito-network
    profiles:
      - agents

  dao-agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
      args:
        INSTALL_CLAUDE_CLI: ${INSTALL_CLAUDE_CLI:-true}
        INSTALL_GEMINI_CLI: ${INSTALL_GEMINI_CLI:-true}
        INSTALL_CODEX_CLI: ${INSTALL_CODEX_CLI:-false}
    container_name: aito-dao
    restart: unless-stopped
    environment:
      <<: *agent-base-env
      AGENT_TYPE: dao
      AGENT_PROFILE: /app/profiles/dao.md
      LOOP_INTERVAL: 21600
      SNAPSHOT_SPACE: ${SNAPSHOT_SPACE:-shibaclassic.eth}
      GNOSIS_SAFE_ADDRESS: ${GNOSIS_SAFE_ADDRESS}
    volumes:
      - ./profiles:/app/profiles:ro
      - dao_memory:/app/memory
      - shared_claude_config:/app/.claude
      - shared_gemini_config:/app/.gemini
      - shared_openai_config:/app/.openai
      - ./workspace:/app/workspace
    depends_on:
      orchestrator:
        condition: service_healthy
    networks:
      - aito-network
    profiles:
      - agents

  # ============================================
  # C-LEVEL LAYER AGENTS
  # ============================================

  cmo-agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
      args:
        INSTALL_CLAUDE_CLI: ${INSTALL_CLAUDE_CLI:-true}
        INSTALL_GEMINI_CLI: ${INSTALL_GEMINI_CLI:-true}
        INSTALL_CODEX_CLI: ${INSTALL_CODEX_CLI:-false}
    container_name: aito-cmo
    restart: unless-stopped
    environment:
      <<: *agent-base-env
      AGENT_TYPE: cmo
      AGENT_PROFILE: /app/profiles/cmo.md
      LOOP_INTERVAL: 14400
      GIT_FILTER: content/*
      TWITTER_BEARER_TOKEN: ${TWITTER_BEARER_TOKEN}
      TWITTER_API_KEY: ${TWITTER_API_KEY}
      TWITTER_API_SECRET: ${TWITTER_API_SECRET}
      TWITTER_ACCESS_TOKEN: ${TWITTER_ACCESS_TOKEN}
      TWITTER_ACCESS_TOKEN_SECRET: ${TWITTER_ACCESS_TOKEN_SECRET}
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
      TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID}
      DIRECTUS_URL: ${DIRECTUS_URL}
      DIRECTUS_TOKEN: ${DIRECTUS_TOKEN}
      DEEPL_API_KEY: ${DEEPL_API_KEY}
    volumes:
      - ./profiles:/app/profiles:ro
      - cmo_memory:/app/memory
      - shared_claude_config:/app/.claude
      - shared_gemini_config:/app/.gemini
      - shared_openai_config:/app/.openai
      - ./workspace:/app/workspace
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      # Orchestrator dependency commented out for standalone testing
      # orchestrator:
      #   condition: service_healthy
    networks:
      - aito-network
    profiles:
      - agents

  cto-agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
      args:
        INSTALL_CLAUDE_CLI: ${INSTALL_CLAUDE_CLI:-true}
        INSTALL_GEMINI_CLI: ${INSTALL_GEMINI_CLI:-true}
        INSTALL_CODEX_CLI: ${INSTALL_CODEX_CLI:-false}
    container_name: aito-cto
    restart: unless-stopped
    environment:
      <<: *agent-base-env
      AGENT_TYPE: cto
      AGENT_PROFILE: /app/profiles/cto.md
      LOOP_INTERVAL: 3600
      GIT_FILTER: website/*
      DIRECTUS_URL: ${DIRECTUS_URL}
      DIRECTUS_TOKEN: ${DIRECTUS_TOKEN}
    volumes:
      - ./profiles:/app/profiles:ro
      - cto_memory:/app/memory
      - shared_claude_config:/app/.claude
      - shared_gemini_config:/app/.gemini
      - shared_openai_config:/app/.openai
      - ./workspace:/app/workspace
    depends_on:
      orchestrator:
        condition: service_healthy
    networks:
      - aito-network
    profiles:
      - agents

  cfo-agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
      args:
        INSTALL_CLAUDE_CLI: ${INSTALL_CLAUDE_CLI:-true}
        INSTALL_GEMINI_CLI: ${INSTALL_GEMINI_CLI:-true}
        INSTALL_CODEX_CLI: ${INSTALL_CODEX_CLI:-false}
    container_name: aito-cfo
    restart: unless-stopped
    environment:
      <<: *agent-base-env
      AGENT_TYPE: cfo
      AGENT_PROFILE: /app/profiles/cfo.md
      LOOP_INTERVAL: 21600
      GIT_FILTER: treasury/*
      ETHERSCAN_API_KEY: ${ETHERSCAN_API_KEY}
      COINGECKO_API_KEY: ${COINGECKO_API_KEY}
      QUICKNODE_HTTP_URL: ${QUICKNODE_HTTP_URL}
      GNOSIS_SAFE_ADDRESS: ${GNOSIS_SAFE_ADDRESS}
    volumes:
      - ./profiles:/app/profiles:ro
      - cfo_memory:/app/memory
      - shared_claude_config:/app/.claude
      - shared_gemini_config:/app/.gemini
      - shared_openai_config:/app/.openai
      - ./workspace:/app/workspace
    depends_on:
      orchestrator:
        condition: service_healthy
    networks:
      - aito-network
    profiles:
      - agents

  coo-agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
      args:
        INSTALL_CLAUDE_CLI: ${INSTALL_CLAUDE_CLI:-true}
        INSTALL_GEMINI_CLI: ${INSTALL_GEMINI_CLI:-true}
        INSTALL_CODEX_CLI: ${INSTALL_CODEX_CLI:-false}
    container_name: aito-coo
    restart: unless-stopped
    environment:
      <<: *agent-base-env
      AGENT_TYPE: coo
      AGENT_PROFILE: /app/profiles/coo.md
      LOOP_INTERVAL: 7200
      GIT_FILTER: community/*
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
      TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID}
      # DISCORD_BOT_TOKEN removed - Discord does not exist
    volumes:
      - ./profiles:/app/profiles:ro
      - coo_memory:/app/memory
      - shared_claude_config:/app/.claude
      - shared_gemini_config:/app/.gemini
      - shared_openai_config:/app/.openai
      - ./workspace:/app/workspace
    depends_on:
      orchestrator:
        condition: service_healthy
    networks:
      - aito-network
    profiles:
      - agents

  cco-agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
      args:
        INSTALL_CLAUDE_CLI: ${INSTALL_CLAUDE_CLI:-true}
        INSTALL_GEMINI_CLI: ${INSTALL_GEMINI_CLI:-true}
        INSTALL_CODEX_CLI: ${INSTALL_CODEX_CLI:-false}
    container_name: aito-cco
    restart: unless-stopped
    environment:
      <<: *agent-base-env
      AGENT_TYPE: cco
      AGENT_PROFILE: /app/profiles/cco.md
      LOOP_INTERVAL: 86400
      GIT_FILTER: legal/*
    volumes:
      - ./profiles:/app/profiles:ro
      - cco_memory:/app/memory
      - shared_claude_config:/app/.claude
      - shared_gemini_config:/app/.gemini
      - shared_openai_config:/app/.openai
      - ./workspace:/app/workspace
    depends_on:
      orchestrator:
        condition: service_healthy
    networks:
      - aito-network
    profiles:
      - agents


  # ============================================
  # PORTAINER (Container Management UI + API)
  # ============================================

  portainer:
    image: portainer/portainer-ce:latest
    container_name: aito-portainer
    restart: unless-stopped
    command: -H unix:///var/run/docker.sock
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    ports:
      - "9000:9000"
      - "9443:9443"
    # Note: Portainer uses a distroless image without wget/curl
    # Health check disabled - external monitoring recommended
    networks:
      - aito-network


  # ============================================
  # DASHBOARD (Web UI)
  # ============================================

  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    container_name: aito-dashboard
    restart: unless-stopped
    ports:
      - "3080:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://orchestrator:8080
    depends_on:
      orchestrator:
        condition: service_healthy
    networks:
      - aito-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://127.0.0.1:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

# ============================================
# NETWORKS
# ============================================

networks:
  aito-network:
    driver: bridge
    name: aito-network

# ============================================
# VOLUMES
# ============================================

volumes:
  # Infrastructure
  portainer_data:
  postgres_data:
  redis_data:
  ollama_data:
  qdrant_data:
  n8n_data:
  orchestrator_logs:

  # Agent Memory (Persistent State)
  ceo_memory:
  dao_memory:
  cmo_memory:
  cto_memory:
  cfo_memory:
  coo_memory:
  cco_memory:

  # Agent Workspaces: Now using shared bind mount ./workspace:/app/workspace
  # (Named volumes removed - all agents share the same local workspace)

  # Claude CLI Auth (Shared across all agents + orchestrator!)
  shared_claude_config:

  # Gemini CLI Auth (Shared across all agents + orchestrator!)
  shared_gemini_config:

  # OpenAI CLI Auth (Shared across all agents + orchestrator!)
  shared_openai_config:

